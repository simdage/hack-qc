{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84859750",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from src.utils.preprocessing import convert_all_files_to_csv\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34304608",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_name,path, case, ext ='.csv'):\n",
    "    df = pd.read_csv(os.path.join(path,case,file_name + ext))\n",
    "    return df\n",
    "def preprocess_signal_files(file_name,path, case, ext ='.csv'):\n",
    "    df = load_data(file_name,path,case,ext\n",
    "                  )\n",
    "    info = df.iloc[0]\n",
    "    data = df.iloc[2: , :]\n",
    "    data.reset_index(inplace = True, drop = True)\n",
    "    columns = data.columns.values\n",
    "    data.rename(columns = {columns[0]:'id',\n",
    "                               columns[1]:'date',\n",
    "                               columns[2]:'value'}, inplace = True)\n",
    "    data['value'] = data['value'].astype(float)\n",
    "    data['date']=pd.to_datetime(data['date'])\n",
    "    data['year'] = data.apply(lambda row: row.date.year, axis = 1)\n",
    "    data['month'] = data.apply(lambda row: row.date.month, axis = 1)\n",
    "    data['day'] = data.apply(lambda row: row.date.day, axis = 1)\n",
    "    data['hour'] = data.apply(lambda row: row.date.hour, axis = 1)\n",
    "    data['minute'] = data.apply(lambda row: row.date.minute, axis = 1)\n",
    "    data.drop(columns=['id'], inplace = True)\n",
    "    \n",
    "    data.to_csv(os.path.join(data_folder,case,file_name+'_processed'+ext))\n",
    "    infos = {'period':info.keys()[1],\n",
    "            'values':info[2]}\n",
    "    with open(os.path.join(data_folder,case,file_name+'_infos.json'), 'w') as f:\n",
    "        json.dump(infos, f)\n",
    "    return info, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20ab133b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = '/home/theaiunicorn/datasets/hackQC2022'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba85a89",
   "metadata": {},
   "source": [
    "# Preprocess each cases \n",
    "to make them data driven ready"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78b8f8b",
   "metadata": {},
   "source": [
    "## Case 1: River"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d10a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "case = 'cas_1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f388e3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "case_1 = {}\n",
    "case_1['sensors'] = [{'raw':['quai_de_beauharnois_2007_2015_brutes',\n",
    "                             'quai_de_beauharnois_2015_2022_brutes'],\n",
    "                      'val':['quai_de_beauharnois_2007_2015_validees',\n",
    "                             'quai_de_beauharnois_2015_2022_validees'],\n",
    "                     'info':['quai_de_beauharnois_2007_2015_brutes_infos',\n",
    "                            'quai_de_beauharnois_2007_2015_validees_infos',\n",
    "                             'quai_de_beauharnois_2015_2022_brutes_infos',\n",
    "                             'quai_de_beauharnois_2015_2022_validees_infos'\n",
    "                            ]},\n",
    "                    {'raw':['beauharnois_aval_2007_2015_brutes',\n",
    "                             'beauharnois_aval_2015_2022_brutes'],\n",
    "                      'val':['beauharnois_aval_2007_2015_validees',\n",
    "                             'beauharnois_aval_2015_2022_validees'],\n",
    "                        'info':['beauharnois_aval_2007_2015_brutes_infos',\n",
    "                            'beauharnois_aval_2007_2015_validees_infos',\n",
    "                             'beauharnois_aval_2015_2022_brutes_infos',\n",
    "                             'beauharnois_aval_2015_2022_validees_infos'\n",
    "                            ]},]\n",
    "case_1['precipitations'] = 'precip.csv'\n",
    "case_1['name'] =  case\n",
    "with open(os.path.join(data_folder,case,'case_summary.json'), 'w') as f:\n",
    "    json.dump(case_1, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f878f0",
   "metadata": {},
   "source": [
    "### Process signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "88685671",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_329768/3300369420.py:2: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(os.path.join(path,case,file_name + ext))\n",
      "/tmp/ipykernel_329768/3300369420.py:2: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(os.path.join(path,case,file_name + ext))\n",
      "/tmp/ipykernel_329768/3300369420.py:2: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(os.path.join(path,case,file_name + ext))\n",
      "/tmp/ipykernel_329768/3300369420.py:2: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(os.path.join(path,case,file_name + ext))\n",
      "/tmp/ipykernel_329768/3300369420.py:2: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(os.path.join(path,case,file_name + ext))\n",
      "/tmp/ipykernel_329768/3300369420.py:2: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(os.path.join(path,case,file_name + ext))\n",
      "/tmp/ipykernel_329768/3300369420.py:2: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(os.path.join(path,case,file_name + ext))\n",
      "/tmp/ipykernel_329768/3300369420.py:2: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(os.path.join(path,case,file_name + ext))\n"
     ]
    }
   ],
   "source": [
    "files = [ f for f in os.listdir(os.path.join(data_folder,case)) if f.find('csv') != -1]\n",
    "for f in files:\n",
    "    if f !='precip.csv':\n",
    "        info, data = preprocess_signal_files(f.replace('.csv',''),data_folder, case)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a4dcd2",
   "metadata": {},
   "source": [
    "### process precipitation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "77d5f2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_data('precip',data_folder,case)\n",
    "info = df.iloc[0]\n",
    "data = df.iloc[2: , :]\n",
    "data.drop(columns = ['Unnamed: 0'], inplace = True)\n",
    "columns = data.columns\n",
    "data.rename(columns={columns[0]:'date',\n",
    "                     columns[1]:info[2][:info[2].find('.METEO')],\n",
    "                     columns[2]:info[3][:info[3].find('.METEO')]\n",
    "                    }, inplace = True)\n",
    "data.to_csv(os.path.join(data_folder,case,'precip'+'_processed.csv'))\n",
    "infos = {'period':info.keys()[1],\n",
    "        'values':[info[2], info[3]]}\n",
    "with open(os.path.join(data_folder,case,'precip'+'_infos.json'), 'w') as f:\n",
    "    json.dump(infos, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ea72b5",
   "metadata": {},
   "source": [
    "## Case 2: Hydrolique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "d4be7e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "case = 'cas_2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "5eb840b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "case_2 = {}\n",
    "case_2['sensors'] = [{'raw':['outardes_2_amont_2007_2015brutes',\n",
    "                             'outardes_2_amont_2015_2022brutes'],\n",
    "                      'val':['outardes_2_amont_2007_2015-valide',\n",
    "                             'outardes_2_amont_2015_2022valide'],\n",
    "                      'red':['outardes_2_redondance_amont_2007_2015',\n",
    "                            'outardes_2_redondance_amont_2015_2022'],\n",
    "                     'info':['outardes_2_amont_2007_2015brutes_infos',\n",
    "                            'outardes_2_amont_2015_2022brutes_infos',\n",
    "                             'outardes_2_amont_2007_2015-valide_infos',\n",
    "                             'outardes_2_amont_2015_2022valide_infos',\n",
    "                             'outardes_2_redondance_amont_2007_2015_infos',\n",
    "                             'outardes_2_redondance_amont_2015_2022_infos'\n",
    "                            ]},\n",
    "                    {'raw':['outardes_2_aval_2007_2015brutes',\n",
    "                             'outardes_2_aval_2015_2022brutes'],\n",
    "                      'val':['outardes_2_aval_2007_2015valide',\n",
    "                             'outardes_2_aval_2015_2022valide'],\n",
    "                     'red':[],\n",
    "                    'info':['outardes_2_aval_2007_2015valide_infos',\n",
    "                                'outardes_2_aval_2007_2015brutes_infos',\n",
    "                                'outardes_2_aval_2015_2022brutes_infos',\n",
    "                                'outardes_2_aval_2015_2022valide_infos'\n",
    "                            ]},]\n",
    "case_2['precipitations'] = 'precip.csv'\n",
    "case_2['name'] =  case\n",
    "with open(os.path.join(data_folder,case,'case_summary.json'), 'w') as f:\n",
    "    json.dump(case_2, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f182d1d2",
   "metadata": {},
   "source": [
    "###  Process signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "7a81c2ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outardes_2_redondance_amont_2007_2015.csv\n",
      "outardes_2_aval_2007_2015valide.csv\n",
      "outardes_2_amont_2015_2022valide.csv\n",
      "outardes_2_aval_2007_2015brutes.csv\n",
      "outardes_2_amont_2007_2015-valide.csv\n",
      "outardes_2_redondance_amont_2015_2022.csv\n",
      "outardes_2_aval_2015_2022brutes.csv\n",
      "outardes_2_amont_2007_2015brutes.csv\n",
      "outardes_2_aval_2015_2022valide.csv\n",
      "outardes_2_amont_2015_2022brutes.csv\n",
      "precip.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_329768/3300369420.py:2: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(os.path.join(path,case,file_name + ext))\n",
      "/tmp/ipykernel_329768/3300369420.py:2: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(os.path.join(path,case,file_name + ext))\n",
      "/tmp/ipykernel_329768/3300369420.py:2: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(os.path.join(path,case,file_name + ext))\n",
      "/tmp/ipykernel_329768/3300369420.py:2: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(os.path.join(path,case,file_name + ext))\n",
      "/tmp/ipykernel_329768/3300369420.py:2: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(os.path.join(path,case,file_name + ext))\n",
      "/tmp/ipykernel_329768/3300369420.py:2: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(os.path.join(path,case,file_name + ext))\n",
      "/tmp/ipykernel_329768/3300369420.py:2: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(os.path.join(path,case,file_name + ext))\n",
      "/tmp/ipykernel_329768/3300369420.py:2: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(os.path.join(path,case,file_name + ext))\n",
      "/tmp/ipykernel_329768/3300369420.py:2: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(os.path.join(path,case,file_name + ext))\n",
      "/tmp/ipykernel_329768/3300369420.py:2: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(os.path.join(path,case,file_name + ext))\n"
     ]
    }
   ],
   "source": [
    "files = [ f for f in os.listdir(os.path.join(data_folder,case)) if f.find('csv') != -1]\n",
    "for f in files:\n",
    "    print(f)\n",
    "for f in files:\n",
    "    print(f)\n",
    "    if f !='precip.csv':\n",
    "        info, data = preprocess_signal_files(f.replace('.csv',''),data_folder, case)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f601d6",
   "metadata": {},
   "source": [
    "### Process precipitation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "fa5d7c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_data('precip',data_folder,case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "9ed9360c",
   "metadata": {},
   "outputs": [],
   "source": [
    "info = df.iloc[0]\n",
    "data = df.iloc[2: , :]\n",
    "data.drop(columns = ['Unnamed: 0'], inplace = True)\n",
    "columns = data.columns\n",
    "data.rename(columns={columns[0]:'date',\n",
    "                     columns[1]:info[2][:info[2].find('.METEO')]\n",
    "                    }, inplace = True)\n",
    "data.to_csv(os.path.join(data_folder,case,'precip'+'_processed.csv'))\n",
    "infos = {'period':info.keys()[1],\n",
    "        'values':[info[2]]}\n",
    "with open(os.path.join(data_folder,case,'precip'+'_infos.json'), 'w') as f:\n",
    "    json.dump(infos, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9046c10c",
   "metadata": {},
   "source": [
    "## Case 3: Reservoir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "b82178a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "case = 'cas_3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "774bbc5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "case_3 = {}\n",
    "case_3['sensors'] = [{'raw':['gouin_so_brute_2010_2015',\n",
    "                             'gouin_so_brute_2007_2010',\n",
    "                             'gouin_so_brute_2015_2022'],\n",
    "                      'val':['gouin_so_valide_2015_2022',\n",
    "                            'gouin_so_valide_2010_2015',\n",
    "                            'gouin_so_valide_2007_2010'],\n",
    "                      'red':['gouin_so_redondance_2007_2015',\n",
    "                            'gouin_so_redondance_2015_2022'],\n",
    "                     'info':['gouin_so_brute_2010_2015_infos',\n",
    "                            'gouin_so_brute_2007_2010_infos',\n",
    "                            'gouin_so_brute_2015_2022_infos',\n",
    "                            'gouin_so_redondance_2007_2015_infos',\n",
    "                            'gouin_so_redondance_2015_2022_infos',\n",
    "                            'gouin_so_valide_2015_2022_infos',\n",
    "                            'gouin_so_valide_2010_2015_infos',\n",
    "                            'gouin_so_valide_2007_2010_infos'\n",
    "                            ]},\n",
    "                    {'raw':['gouin_amont_brute_2015_2022',\n",
    "                            'gouin_amont_brute_2007_2010',\n",
    "                            'gouin_amont_brute_2010_2015'],\n",
    "                      'val':['gouin_amont_valide_2007_2010',\n",
    "                            'gouin_amont_valide_2010_2015',\n",
    "                            'gouin_amont_valide_2015_2022'],\n",
    "                     'red':['gouin_amont_redondance_2015_2022'],\n",
    "                    'info':['gouin_amont_brute_2015_2022_infos',\n",
    "                            'gouin_amont_brute_2007_2010_infos',\n",
    "                            'gouin_amont_brute_2010_2015_infos',\n",
    "                            'gouin_amont_valide_2007_2010_infos',\n",
    "                            'gouin_amont_valide_2010_2015_infos',\n",
    "                            'gouin_amont_valide_2015_2022_infos',\n",
    "                            'gouin_amont_redondance_2015_2022_infos'\n",
    "                            ]},]\n",
    "case_3['precipitations'] = 'precip.csv'\n",
    "case_3['name'] =  case\n",
    "with open(os.path.join(data_folder,case,'case_summary.json'), 'w') as f:\n",
    "    json.dump(case_3, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ca6ddc",
   "metadata": {},
   "source": [
    "### Process signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "ed70947d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gouin_so_brute_2010_2015.csv\n",
      "gouin_so_brute_2007_2010.csv\n",
      "gouin_so_redondance_2007_2015.csv\n",
      "gouin_amont_valide_2007_2010.csv\n",
      "gouin_so_valide_2010_2015.csv\n",
      "gouin_amont_brute_2015_2022.csv\n",
      "gouin_so_valide_2015_2022.csv\n",
      "gouin_amont_redondance_2015_2022.csv\n",
      "gouin_amont_valide_2010_2015.csv\n",
      "gouin_amont_valide_2015_2022.csv\n",
      "gouin_amont_brute_2010_2015.csv\n",
      "gouin_so_brute_2015_2022.csv\n",
      "gouin_so_valide_2007_2010.csv\n",
      "precip.csv\n",
      "gouin_so_redondance_2015_2022.csv\n",
      "gouin_amont_brute_2007_2010.csv\n",
      "gouin_so_brute_2010_2015.csv\n",
      "gouin_so_brute_2007_2010.csv\n",
      "gouin_so_redondance_2007_2015.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_329768/3300369420.py:2: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(os.path.join(path,case,file_name + ext))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gouin_amont_valide_2007_2010.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_329768/3300369420.py:2: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(os.path.join(path,case,file_name + ext))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gouin_so_valide_2010_2015.csv\n",
      "gouin_amont_brute_2015_2022.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_329768/3300369420.py:2: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(os.path.join(path,case,file_name + ext))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gouin_so_valide_2015_2022.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_329768/3300369420.py:2: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(os.path.join(path,case,file_name + ext))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gouin_amont_redondance_2015_2022.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_329768/3300369420.py:2: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(os.path.join(path,case,file_name + ext))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gouin_amont_valide_2010_2015.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_329768/3300369420.py:2: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(os.path.join(path,case,file_name + ext))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gouin_amont_valide_2015_2022.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_329768/3300369420.py:2: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(os.path.join(path,case,file_name + ext))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gouin_amont_brute_2010_2015.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_329768/3300369420.py:2: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(os.path.join(path,case,file_name + ext))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gouin_so_brute_2015_2022.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_329768/3300369420.py:2: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(os.path.join(path,case,file_name + ext))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gouin_so_valide_2007_2010.csv\n",
      "precip.csv\n",
      "gouin_so_redondance_2015_2022.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_329768/3300369420.py:2: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(os.path.join(path,case,file_name + ext))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gouin_amont_brute_2007_2010.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_329768/3300369420.py:2: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(os.path.join(path,case,file_name + ext))\n"
     ]
    }
   ],
   "source": [
    "files = [ f for f in os.listdir(os.path.join(data_folder,case)) if f.find('csv') != -1]\n",
    "for f in files:\n",
    "    print(f)\n",
    "for f in files:\n",
    "    print(f)\n",
    "    if f !='precip.csv':\n",
    "        info, data = preprocess_signal_files(f.replace('.csv',''),data_folder, case)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4647720e",
   "metadata": {},
   "source": [
    "### Process precipitation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "2b71ee91",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_data('precip',data_folder,case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "8dac7e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "info = df.iloc[0]\n",
    "data = df.iloc[2: , :]\n",
    "data.drop(columns = ['Unnamed: 0'], inplace = True)\n",
    "columns = data.columns\n",
    "data.rename(columns={columns[0]:'date',\n",
    "                     columns[1]:info[2][:info[2].find('.METEO')],\n",
    "                     columns[2]:info[3][:info[3].find('.METEO')],\n",
    "                     columns[3]:info[4][:info[4].find('.METEO')]\n",
    "                    }, inplace = True)\n",
    "data.to_csv(os.path.join(data_folder,case,'precip'+'_processed.csv'))\n",
    "infos = {'period':info.keys()[1],\n",
    "        'values':[info[2],info[3],info[4]]}\n",
    "with open(os.path.join(data_folder,case,'precip'+'_infos.json'), 'w') as f:\n",
    "    json.dump(infos, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9f0515",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "class SignalCase1Dataset(Dataset):\n",
    "    def __init__(self, \n",
    "                 preci_file,\n",
    "                 raw_file,\n",
    "                 validated_file,\n",
    "                 root_dir):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.annotations_file = pd.read_csv(csv_file)\n",
    "        self.labels = labels\n",
    "        self.root_dir = root_dir\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.annotations_file)\n",
    "    \n",
    "    def preprocessing(self,img,label=None):\n",
    "        #todo\n",
    "        continue\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        if self.transform:\n",
    "            image,_ = self.preprocessing(image)\n",
    "        else:\n",
    "            image = torch.from_numpy(image).float()\n",
    "        \n",
    "        labels = int(self.annotations_file.iloc[idx, 1:] - 1)\n",
    "        return image, labels"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unicorn",
   "language": "python",
   "name": "unicorn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
